{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7da95677",
   "metadata": {},
   "source": [
    "# بسم الله الرحمن الرحیم"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7296867",
   "metadata": {},
   "source": [
    "# محمد مهدی شفیقی - پروژه نهایی درس مباحث ویژه"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0189a2b0",
   "metadata": {},
   "source": [
    "# تحلیل شبکه همکاری علمی CA-HepTh\n",
    "\n",
    "این پروژه به تحلیل ویژگی‌های ساختاری و دینامیکی شبکه هم‌نویسندگی در حوزه فیزیک انرژی بالا می‌پردازد."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f522e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# فقط در صورت نیاز اجرا کن\n",
    "!pip install --quiet networkx pandas numpy matplotlib python-louvain tqdm scipy\n",
    "# برای عملکرد بهتر (اختیاری، سریع‌تر و مقیاس‌پذیرتر)\n",
    "!pip install --quiet python-igraph leidenalg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7976dd41",
   "metadata": {},
   "source": [
    "## تنظیم مسیر داده — مسیر را طبق محل واقعی تغییر بده\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410cd21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = \"../data/cit-HepTh-abstracts\"   # محتوای پوشه: 1992/, 1993/, ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b133e07",
   "metadata": {},
   "source": [
    "# ایمپورت‌های پایه\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5cec70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, gc, pickle, math, time\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9169c17",
   "metadata": {},
   "source": [
    "# توابع مفید\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91e4d0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pickle(obj, path):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(obj, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_pickle(path):\n",
    "    with open(path, \"rb\") as f:\n",
    "        return pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6432abd",
   "metadata": {},
   "source": [
    "# چک محیط و نمونه‌برداری فایل‌ها + تابع استخراج نویسنده (اجرای اولیه)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9a1665e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found year-folders (sample): ['1992', '1993', '1994', '1995', '1996', '1997']  ... total: 12\n",
      "Total .abs files: 29555\n",
      "Files per year (first 10):\n",
      "  1992: 1367 files\n",
      "  1993: 2058 files\n",
      "  1994: 2377 files\n",
      "  1995: 2303 files\n",
      "  1996: 2606 files\n",
      "  1997: 2673 files\n",
      "  1998: 2758 files\n",
      "  1999: 2803 files\n",
      "  2000: 3126 files\n",
      "  2001: 3153 files\n",
      "\n",
      "Sample files and extracted authors:\n",
      "\n",
      "Year 1992 | file: 9201001.abs\n",
      " Extracted authors: ['C. Itzykson', 'J.-B. Zuber']\n",
      "\n",
      "Year 1993 | file: 9301001.abs\n",
      " Extracted authors: ['G.K.Savvidy', 'K.G.Savvidy']\n",
      "\n",
      "Year 1994 | file: 9401001.abs\n",
      " Extracted authors: ['Jorge Ananias Neto']\n",
      "\n",
      "Year 1995 | file: 9501001.abs\n",
      " Extracted authors: []\n",
      "\n",
      "Year 1996 | file: 9601001.abs\n",
      " Extracted authors: []\n",
      "\n",
      "Year 1997 | file: 9701001.abs\n",
      " Extracted authors: ['M. Zyskin We consider d-dimensional Riemanian manifolds which admit d-2 commuting space-like Killing vector fields', 'orthogonal to a surface', 'containing two one-parametric families of light-like curves. The condition of the Ricci tensor to be zero gives Ernst equations for the metric. We write explicitly a family of local solutions of this equations corresponding to arbitrary initial data on two characteristics in terms of a series. These metrics describe scattering of 2 gravitational waves', 'thus we expect they are very interesting. Ernst equations can be written as equations of motion for some 2D Lagrangian', 'which governs fluctuations of the metric', 'constant in the Killing directions. This Lagrangian looks essentially as a 2D chiral field model', 'thus is possibly treatable in the quantum case by standart methods. It is conceivable that it may describe physics of some specially arranged scattering experiment', 'thus giving an insight for 4D gravity', 'not treatable by standart quantum field theory methods. The renormalization flow for our Lagrangian is different from the flow for the unitary chiral field model', 'the difference is essentially due to the fact that here the field is taking values in a non-compact space of symmetric matrices. We investigate the model']\n",
      "\n",
      "Rough IO check: enumerated ~200 files in 0.00s\n",
      "\n",
      "A-0 done. If sample author extraction looks reasonable, reply with 'A-0 OK' and we'll run A-1: build efficient temporal-edge lists (ids + per-year CSV dump).\n"
     ]
    }
   ],
   "source": [
    "# A-0: Environment check + sample parsing of .abs files\n",
    "# اجرا در یک سلول جدید در Jupyter notebook\n",
    "\n",
    "import os, re, time\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "except Exception:\n",
    "    # tqdm اختیاری است؛ اگر نصب نیست، از آن صرفنظر می‌کنیم\n",
    "    def tqdm(x, **_): \n",
    "        return x\n",
    "\n",
    "# مسیرِ پوشه‌ی cit-HepTh-abstracts را بر اساس ساختار تو تنظیم کن:\n",
    "DATA_ROOT = \"../data/cit-HepTh-abstracts\"   # اگر مسیرت متفاوت است این را تغییر بده\n",
    "\n",
    "# 1) شمارش فایل‌ها و نام پوشه‌ها (سال‌ها)\n",
    "years = sorted([d for d in os.listdir(DATA_ROOT) if os.path.isdir(os.path.join(DATA_ROOT, d))])\n",
    "print(\"Found year-folders (sample):\", years[:6], \" ... total:\", len(years))\n",
    "\n",
    "year_file_counts = {}\n",
    "total_files = 0\n",
    "for y in years:\n",
    "    p = os.path.join(DATA_ROOT, y)\n",
    "    files = [f for f in os.listdir(p) if f.endswith('.abs')]\n",
    "    year_file_counts[y] = len(files)\n",
    "    total_files += len(files)\n",
    "\n",
    "print(f\"Total .abs files: {total_files}\")\n",
    "print(\"Files per year (first 10):\")\n",
    "for y in years[:10]:\n",
    "    print(f\"  {y}: {year_file_counts[y]} files\")\n",
    "\n",
    "# 2) Robust author-extraction function (tries چند الگو)\n",
    "_author_patterns = [\n",
    "    re.compile(r'Authors:\\s*(.*?)\\n(?:Title:|Comments:|\\\\\\n|$)', re.DOTALL | re.IGNORECASE),\n",
    "    re.compile(r'Authors:\\s*(.*)', re.IGNORECASE),\n",
    "]\n",
    "\n",
    "def extract_authors_from_text(txt):\n",
    "    \"\"\"\n",
    "    تلاش می کند رشته‌ی نویسندگان را از متن استخراج کند.\n",
    "    بازگشتی: لیست اسامی نویسنده‌ها (هر اسم تمیزشده)\n",
    "    \"\"\"\n",
    "    # بعضی فایل‌ها از backslash \\\\ برای جدا کردن بخش‌ها استفاده می‌کنند، آن‌ها را به newline تبدیل کن\n",
    "    t = txt.replace('\\\\\\n', '\\n').replace('\\\\', '\\n')\n",
    "    authors_text = None\n",
    "    for pat in _author_patterns:\n",
    "        m = pat.search(t)\n",
    "        if m:\n",
    "            authors_text = m.group(1)\n",
    "            break\n",
    "    if not authors_text:\n",
    "        # fallback: خطی جستجو کن\n",
    "        for line in t.splitlines():\n",
    "            if line.strip().lower().startswith(\"authors:\"):\n",
    "                authors_text = line.split(':',1)[1]\n",
    "                break\n",
    "    if not authors_text:\n",
    "        return []  # هیچ نویسنده‌ای پیدا نشد\n",
    "\n",
    "    # پاک‌سازی و جداسازی: \"and\" و کاما و ; را مدنظر قرار بده\n",
    "    authors_text = authors_text.replace('\\n', ' ')\n",
    "    # بعضی فرمت‌ها \"A and B\" دارند\n",
    "    authors_text = re.sub(r'\\sand\\s', ',', authors_text)\n",
    "    # جداکننده‌ها: ',' یا ';' یا ' and '\n",
    "    parts = re.split(r',|;|\\band\\b', authors_text)\n",
    "    authors = []\n",
    "    for p in parts:\n",
    "        p = p.strip()\n",
    "        if not p:\n",
    "            continue\n",
    "        # حذف موارد غیرِ اسم (مثل affiliation داخل پرانتز)\n",
    "        p = re.sub(r'\\(.*?\\)', '', p).strip()\n",
    "        # normalize spaces\n",
    "        p = re.sub(r'\\s+', ' ', p)\n",
    "        authors.append(p)\n",
    "    # unique preserving order\n",
    "    seen = set()\n",
    "    authors_clean = []\n",
    "    for a in authors:\n",
    "        key = a.lower()\n",
    "        if key not in seen:\n",
    "            seen.add(key)\n",
    "            authors_clean.append(a)\n",
    "    return authors_clean\n",
    "\n",
    "# 3) نمایش چند نمونه فایل و نتیجه‌ی استخراج نویسنده\n",
    "SAMPLES_TO_SHOW = 6\n",
    "sample_files = []\n",
    "for y in years:\n",
    "    d = os.path.join(DATA_ROOT, y)\n",
    "    files = [f for f in os.listdir(d) if f.endswith('.abs')]\n",
    "    if files:\n",
    "        sample_files.append((y, files[:1][0], os.path.join(d, files[0])))\n",
    "    if len(sample_files) >= SAMPLES_TO_SHOW:\n",
    "        break\n",
    "\n",
    "print(\"\\nSample files and extracted authors:\")\n",
    "for y, fname, fpath in sample_files:\n",
    "    try:\n",
    "        with open(fpath, 'r', encoding='utf-8', errors='ignore') as fh:\n",
    "            txt = fh.read(4000)  # فقط 4k اول برای نمایش\n",
    "    except Exception as e:\n",
    "        txt = f\"(error reading: {e})\"\n",
    "    authors = extract_authors_from_text(txt)\n",
    "    print(f\"\\nYear {y} | file: {fname}\")\n",
    "    print(\" Extracted authors:\", authors[:10])\n",
    "\n",
    "# 4) (اختیاری) تست زمان خواندن تعداد نمونه‌ای از فایل‌ها\n",
    "NTEST = 200   # تعداد فایل‌ها که برای سنجش سرعت پردازش بررسی می‌کنیم\n",
    "t0 = time.time()\n",
    "count = 0\n",
    "for y in years:\n",
    "    d = os.path.join(DATA_ROOT, y)\n",
    "    for fn in os.listdir(d):\n",
    "        if not fn.endswith('.abs'):\n",
    "            continue\n",
    "        count += 1\n",
    "        if count > NTEST:\n",
    "            break\n",
    "    if count > NTEST:\n",
    "        break\n",
    "t1 = time.time()\n",
    "print(f\"\\nRough IO check: enumerated ~{min(count, NTEST)} files in {t1-t0:.2f}s\")\n",
    "\n",
    "print(\"\\nA-0 done. If sample author extraction looks reasonable, reply with 'A-0 OK' and we'll run A-1: build efficient temporal-edge lists (ids + per-year CSV dump).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44d49cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
